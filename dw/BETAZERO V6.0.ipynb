{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e3834b",
   "metadata": {},
   "source": [
    "# WHATEVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84429597",
   "metadata": {},
   "source": [
    "#  🤣MOROKEI😋 - 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e1b68",
   "metadata": {},
   "source": [
    "설명 (Description)\n",
    "\n",
    "GYMX1 부터 GYMX9 까지의 업그레이드를 통해 마지막에 BETAZERO V0 가 된 겁니다.\n",
    "CHAT GPT 4 의 도움을 굉장히 많이 받았습니다.\n",
    "\n",
    "자세한 사항은 www.morokei.com/DeepLearning/BetaZero 에서 확인하세요.\n",
    "\n",
    "20161728, 화공생명공학과, 서강대학교\n",
    "\n",
    "Email : thenoblesse5322@gmail.com\n",
    "\n",
    "2023.04.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5727ba",
   "metadata": {},
   "source": [
    "추가된 부분\n",
    "1. 구조 대폭 수정 : legal moves만 가지고 움직이는 policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d50da4",
   "metadata": {},
   "source": [
    "신경망과 DQN 에이전트를 초기화합니다. 두 명의 에이전트가 경쟁하도록 설정하여 서로 학습하게 합니다.\n",
    "\n",
    "게임 환경을 초기화하고 여러 에피소드를 통해 에이전트를 훈련시킵니다. 에이전트는 현재 상태에서 가능한 최적의 행동을 선택하고, 행동에 대한 결과로 다음 상태와 보상을 얻습니다. 이 경험들은 ReplayBuffer에 저장됩니다.\n",
    "\n",
    "버퍼에 충분한 경험이 쌓이면, 에이전트는 이러한 경험들을 샘플링하여 신경망을 업데이트하고 학습합니다. 학습 과정에서 기대되는 Q-값과 목표 Q-값 사이의 차이를 최소화하도록 신경망의 가중치를 조정합니다.\n",
    "\n",
    "목표 네트워크는 일정한 간격으로 로컬 네트워크의 가중치를 부드럽게 가져와 업데이트합니다. 이렇게 하여 학습 과정의 안정성을 유지하고, 최신 가중치를 목표 네트워크에 반영합니다.\n",
    "\n",
    "각 에피소드가 종료될 때마다, 에이전트간의 스코어를 기록하고, 일정한 에피소드마다 평균 스코어를 출력하여 에이전트의 학습 진행 상황을 확인할 수 있습니다.\n",
    "\n",
    "일정한 에피소드마다 신경망 모델과 ReplayBuffer를 저장합니다. 이를 통해 훈련 중간에 중단되더라도 이후에 훈련을 이어갈 수 있으며, 최적화된 모델을 사용하여 게임을 진행할 수 있습니다.\n",
    "\n",
    "사용자와 상호작용하는 '실행' 함수를 통해, 모델을 학습시키거나, 하이퍼파라미터를 최적화하거나, 모델을 저장 및 불러오는 작업을 수행할 수 있습니다. 이를 통해 사용자는 에이전트의 학습 상태를 쉽게 관리하고, 원하는 시점에서 모델을 사용하여 게임을 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df82b5",
   "metadata": {},
   "source": [
    "# 1. CHESS PART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3c804",
   "metadata": {},
   "source": [
    "## Import Module Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96720d",
   "metadata": {},
   "source": [
    "### Import Gym Module Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb4f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경로 :  D:\\chess_ai\\BetaZero (new)\\BETAZERO V2+ \n",
      "\n",
      "일반모듈경로 :  C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym \n",
      "\n",
      "특별모듈경로 :  D:\\chess_ai\\BetaZero (new)\\BETAZERO V2+/data/used modules\\gym_chess_morokei \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym , random, time, os, sys, glob\n",
    "import numpy as np, pandas as pd\n",
    "import chess, datetime, chess.pgn\n",
    "import pickle, re\n",
    "\n",
    "경로 = os.getcwd() ; print (\"경로 : \", 경로, \"\\n\")\n",
    "sys.path.insert(0, \"\"+경로+\"/data/used modules/\")\n",
    "\n",
    "import gym_chess_morokei as gym_chess\n",
    "from gym_chess_morokei.envs import Chess\n",
    "\n",
    "print (\"일반모듈경로 : \" , os.path.dirname(gym.__file__), \"\\n\")\n",
    "print (\"특별모듈경로 : \", os.path.dirname(gym_chess.__file__), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c6867",
   "metadata": {},
   "source": [
    "### Import Torch Module Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f13f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc0fd6",
   "metadata": {},
   "source": [
    "### Import Other Module Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff516ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math ; import matplotlib, matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count ; from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793ede2",
   "metadata": {},
   "source": [
    "## Import Gym Environment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760c6f7",
   "metadata": {},
   "source": [
    "### 체스보드 생성 (LEGACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886864db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n"
     ]
    }
   ],
   "source": [
    "env = gym_chess._make_env()\n",
    "observation = env.reset()\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d909fa2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'chess.Board'>\n",
      "<class 'chess.Board'>\n"
     ]
    }
   ],
   "source": [
    "print(type(env._board))\n",
    "print(type(observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e05679",
   "metadata": {},
   "source": [
    "### 인코더 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b21341",
   "metadata": {},
   "source": [
    "기존 인코더에, 텐서 하나를 새로 맨 앞에 추가 했다ㅏ. 맨 앞 텐서는 흑과 백 정보를 가지고 있다.\n",
    "\n",
    "이게 없으면, 모델이 아무리 초고수더라도 자기가 백인지 흑인지 맨 처음에 찍어야 하는 불상사가 생기기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40087d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(chessboard_observation):\n",
    "    tensor_observation = torch.zeros((14, 8, 8))\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = chessboard_observation.piece_at(i * 8 + j)\n",
    "            if piece is not None:\n",
    "                # Encode piece type and color as one-hot vector\n",
    "                index = piece.piece_type - 1 + (piece.color - 1) * 6 + 1\n",
    "                tensor_observation[index][i][j] = 1\n",
    "            else:\n",
    "                # Encode empty square as one-hot vector\n",
    "                tensor_observation[7][i][j] = 1\n",
    "\n",
    "    # Encode the current player's color\n",
    "    if chessboard_observation.turn:  # White\n",
    "        tensor_observation[0] = 1\n",
    "    else:  # Black\n",
    "        tensor_observation[0] = 0\n",
    "\n",
    "    tensor_observation = tensor_observation.unsqueeze(0)  # add batch dimension\n",
    "    return tensor_observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4a5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 1., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(encoder(observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feea9b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nChessboard UCI Table\\n\\n8        [[56, 57, 58, 59, 60, 61, 62, 63],\\n7         [48, 49, 50, 51, 52, 53, 54, 55],\\n6         [40, 41, 42, 43, 44, 45, 46, 47],\\n5         [32, 33, 34, 35, 36, 37, 38, 39],\\n4         [24, 25, 26, 27, 28, 29, 30, 31],\\n3         [16, 17, 18, 19, 20, 21, 22, 23],\\n2         [8,  9,  10, 11, 12, 13, 14, 15],\\n1         [0,  1,  2,  3,  4,  5,  6,  7]]\\n           a   b   c   d   e   f   g   h\\n           \\n           \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Chessboard UCI Table\n",
    "\n",
    "8        [[56, 57, 58, 59, 60, 61, 62, 63],\n",
    "7         [48, 49, 50, 51, 52, 53, 54, 55],\n",
    "6         [40, 41, 42, 43, 44, 45, 46, 47],\n",
    "5         [32, 33, 34, 35, 36, 37, 38, 39],\n",
    "4         [24, 25, 26, 27, 28, 29, 30, 31],\n",
    "3         [16, 17, 18, 19, 20, 21, 22, 23],\n",
    "2         [8,  9,  10, 11, 12, 13, 14, 15],\n",
    "1         [0,  1,  2,  3,  4,  5,  6,  7]]\n",
    "           a   b   c   d   e   f   g   h\n",
    "           \n",
    "           \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf8dc1",
   "metadata": {},
   "source": [
    "### 아웃풋 / 리버스 아웃풋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9cdbc",
   "metadata": {},
   "source": [
    "#### 아웃풋 리스트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aaea6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4209\n"
     ]
    }
   ],
   "source": [
    "# csv 파일 있으면 그거 쓰고 없으면 새로 리스트 만들기\n",
    "\n",
    "csv_path = \"data/모든 체스 UCI 목록.csv\"\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    outcome_df = pd.read_csv(csv_path)\n",
    "    outcome = [chess.Move.from_uci(move) for move in outcome_df['moves']]\n",
    "else:\n",
    "    outcome = [chess.Move(0, 0)]\n",
    "\n",
    "    for start in range(64):\n",
    "        for end in range(64):\n",
    "            if start == end:\n",
    "                continue\n",
    "            outcome.append(chess.Move(start, end))\n",
    "\n",
    "    promotion_pairs = [(48, 56), (48, 57), (49, 56), (49, 57), (49, 58),\n",
    "             (50, 57), (50, 58), (50, 59), (51, 58), (51, 59),\n",
    "             (51, 60), (52, 59), (52, 60), (52, 61), (53, 60),\n",
    "             (53, 61), (53, 62), (54, 61), (54, 62), (54, 63),\n",
    "             (55, 62), (55, 63), (8, 0), (8, 1), (9, 0), (9, 1),\n",
    "             (9, 2), (10, 1), (10, 2), (10, 3), (11, 2), (11, 3),\n",
    "             (11, 4), (12, 3), (12, 4), (12, 5), (13, 4), (13, 5),\n",
    "             (13, 6), (14, 5), (14, 6), (14, 7), (15, 6), (15, 7)]\n",
    "\n",
    "    for pair in promotion_pairs:\n",
    "        for promote_to in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:\n",
    "            outcome.append(chess.Move(pair[0], pair[1], promotion=promote_to))\n",
    "\n",
    "    # Save the outcome list to a CSV file\n",
    "    (pd.DataFrame(outcome, columns=['moves'])).to_csv(csv_path, index=False)\n",
    "print(len(outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56e0b8",
   "metadata": {},
   "source": [
    "총 가능 UCI 는 4208개로 측정되었고, 기권을 의미하는 0 --> 0 를 하나 추가하여 총 4209 개의 outcome 이 있다.\n",
    "\n",
    "프로모션 되는 무브 저장\n",
    "48 56)\n",
    "48 57)\n",
    "49 56)\n",
    "49 57)\n",
    "49 58)\n",
    "50 57)\n",
    "50 58)\n",
    "50 59)\n",
    "51 58)\n",
    "51 59)\n",
    "51 60)\n",
    "52 59)\n",
    "52 60)\n",
    "52 61)\n",
    "53 60)\n",
    "53 61)\n",
    "53 62)\n",
    "54 61)\n",
    "54 62)\n",
    "54 63)\n",
    "55 62)\n",
    "55 63)\n",
    "8 0)\n",
    "8 1)\n",
    "9 0)\n",
    "9 1)\n",
    "9 2)\n",
    "10 1)\n",
    "10 2 )\n",
    "10 3)\n",
    "11 2)\n",
    "11 3)\n",
    "11 4 )\n",
    "12 3)\n",
    "12 4 )\n",
    "12 5)\n",
    "13 4 )\n",
    "13 5)\n",
    "13 6)\n",
    "14 5)\n",
    "14 6)\n",
    "14 7)\n",
    "15 6)\n",
    "15 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0473c3",
   "metadata": {},
   "source": [
    "#### 리버스 아웃풋 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b475d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_move(move_index):\n",
    "    return outcome[move_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88560e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_moves_indices(board):\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_moves_indices = [outcome.index(move) for move in legal_moves]\n",
    "    return legal_moves_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b40d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[401,\n",
       " 399,\n",
       " 81,\n",
       " 79,\n",
       " 968,\n",
       " 904,\n",
       " 840,\n",
       " 776,\n",
       " 712,\n",
       " 648,\n",
       " 584,\n",
       " 520,\n",
       " 976,\n",
       " 912,\n",
       " 848,\n",
       " 784,\n",
       " 720,\n",
       " 656,\n",
       " 592,\n",
       " 528]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legal_moves_indices(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102b402",
   "metadata": {},
   "source": [
    "Computer_1 = []\n",
    "Computer_2 = []\n",
    "observation, reward, done, _ = env.step(action_move = chess.Move(outcome[Computer_1_선택결과]))\n",
    "observation, reward, done, _ = env.step(action_move = chess.Move(outcome[Computer_2_선택결과]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e4784",
   "metadata": {},
   "source": [
    "참고 :  INDEX NUMBERING\n",
    "\n",
    "    0 : p\n",
    "    1 : n\n",
    "    2 : b\n",
    "    3 : r\n",
    "    4 : q\n",
    "    5 : k\n",
    "    6 : 빈공간\n",
    "    7 : P\n",
    "    8 : N\n",
    "    9 : B\n",
    "    10 : R\n",
    "    11 : Q\n",
    "    12 : K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc99df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'*': 0.0, '1/2-1/2': -0.5, '1-0': 1.0, '0-1': -1.0, 'Illegal Move': -1.0}\n",
      "\n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(Chess._rewards)\n",
    "print(\"\\n\")\n",
    "print(env._reward())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ee488",
   "metadata": {},
   "source": [
    "# 2. Torch Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8349fb9",
   "metadata": {},
   "source": [
    "### Initialize CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a93eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fceaef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "니 파이토치 버전 이랑 쿠다 호환 버전이다  :  1.13.1+cu117\n",
      "CUDA 할당 된 그래픽 카드다   :  NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "print(\"니 파이토치 버전 이랑 쿠다 호환 버전이다  : \" , torch.          __version__, end=\"\\n\")\n",
    "print(\"CUDA 할당 된 그래픽 카드다   : \", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dcbf7",
   "metadata": {},
   "source": [
    "## CNN 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aee28c",
   "metadata": {},
   "source": [
    "0410\n",
    "인코더에서 맨 첫번 째 텐서에 흑과 백의 정보를 추가 시켰다.\n",
    "그래서 CNN 에서도 14개의 텐서를 받게 되고, 첫번 째 꺼는 그냥 8x8 로 계산시키고\n",
    "나머지 13개는 원래 하던 대로 하는 코드로 변경했다.\n",
    "\n",
    "0413\n",
    "결과가 안좋아서\n",
    "1. Residual connection 사용\n",
    "2. hidden layer 추가 (아니 이전에 히든 레이어가 아예 없더라 ㅋㅋㅋㅋㅋㅋㅋㅋ 무슨 벌레색휘도 아니고 ㅋㅋㅋㅋㅋㅋㅋㅋ 🤣🤣🤣 )\n",
    "\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6a31a",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa4c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(14, 14, kernel_size=k, padding=0) for k in range(1, 9)\n",
    "        ])\n",
    "\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Conv2d(14, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.hidden3 = nn.Linear(64 * 8 * 8, 32 * 8 * 8)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 4209)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_outputs = []\n",
    "        max_height, max_width = 8, 8\n",
    "\n",
    "        for conv in self.convs:\n",
    "            out = torch.relu(conv(x))\n",
    "            height_diff = max_height - out.size(2)\n",
    "            width_diff = max_width - out.size(3)\n",
    "            out = F.pad(out, (0, width_diff, 0, height_diff))\n",
    "            conv_outputs.append(out)\n",
    "\n",
    "        x = torch.cat(conv_outputs, dim=1)\n",
    "        x = self.hidden1(x) + x\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden2(x) + x\n",
    "        \n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.hidden3(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 32, 8, 8)\n",
    "\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb618a71",
   "metadata": {},
   "source": [
    "## DQN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098eec5",
   "metadata": {},
   "source": [
    "1. self.trained = False 를 통해서 빈 모델을 저장하게 되는 일을 막음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf444ac",
   "metadata": {},
   "source": [
    "### DQN 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f125ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, cnn, buffer_size=1000000, batch_size=10000, gamma=0.99, learning_rate=0.001, tau=0.01, device=device):\n",
    "        self.local_net = cnn.to(device)\n",
    "        self.target_net = CNN().to(device)\n",
    "        self.target_net.load_state_dict(self.local_net.state_dict())\n",
    "        self.optimizer = optim.Adam(self.local_net.parameters(), lr=learning_rate)\n",
    "        self.buffer = ReplayBuffer(buffer_size, batch_size,device)\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "        self.trained = False\n",
    "\n",
    "    def step(self, env, state, action, reward, next_state, done):\n",
    "        self.buffer.add(state, action, reward, next_state, done)\n",
    "        if len(self.buffer) >= self.batch_size:\n",
    "            experiences = self.buffer.sample()\n",
    "            self.learn(experiences)\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.target_net(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "\n",
    "        # Compute Q targets for current states\n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.local_net(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update target network\n",
    "        self.soft_update(self.local_net, self.target_net, self.tau)\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
    "\n",
    "    def act(self, env, state, eps=0.):\n",
    "        state = torch.from_numpy(state).float().to(self.device).view(1, 14, 8, 8)\n",
    "        self.local_net.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.local_net(state)\n",
    "        self.local_net.train()\n",
    "\n",
    "        if random.random() > eps:\n",
    "            legal_moves = legal_moves_indices(env)\n",
    "            legal_action_values = action_values[0][legal_moves]\n",
    "            best_legal_move_index = torch.argmax(legal_action_values).item()\n",
    "            return legal_moves[best_legal_move_index]\n",
    "        else:\n",
    "            return random.choice(legal_moves_indices(env))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c4752",
   "metadata": {},
   "source": [
    "### Replay Buffer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c00d727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience:\n",
    "    def __init__(self, state, action, reward, next_state, done):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.next_state = next_state\n",
    "        self.done = done\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self.state, self.action, self.reward, self.next_state, self.done\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.state, self.action, self.reward, self.next_state, self.done = state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size, batch_size, device=device):\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "    def experience(self, state, action, reward, next_state, done):\n",
    "        return Experience(state, action, reward, next_state, done)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences])).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences]).astype(np.uint8)).float().to(self.device)\n",
    "\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed9aa7",
   "metadata": {},
   "source": [
    "## Run Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daabe6e",
   "metadata": {},
   "source": [
    "2.  save buffer and model 이 true 면 (default) 10000 마다 저장 하는데\n",
    "    Hyperparameter Optimization 하는 동안은 이 값이 false 가 되어서 저장을 안 하게 됨\n",
    "    \n",
    "\n",
    "3.  save_game_log 추가됨.\n",
    "    이제 오류 없이 매 episode 끝나면 해당 게임의 PGN (메타데이터 포함) 이 저장 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e65c69",
   "metadata": {},
   "source": [
    "### Run Game 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75838fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunGame:\n",
    "    def __init__(self, dqn_agent1, dqn_agent2, env, num_episodes, episode_movies, eps_start=1.0, eps_end=0.01, eps_decay=0.995, save_model_and_buffer=True):\n",
    "        self.dqn_agent1 = dqn_agent1\n",
    "        self.dqn_agent2 = dqn_agent2\n",
    "        self.env = env\n",
    "        self.num_episodes = num_episodes\n",
    "        self.episode_movies = episode_movies\n",
    "        self.eps_start = eps_start\n",
    "        self.eps_end = eps_end\n",
    "        self.eps_decay = eps_decay\n",
    "        self.save_model_and_buffer = save_model_and_buffer\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def save_game_log(env, episode_number, log_dir=\"data/logs/PGN logs\"):\n",
    "        date_str = datetime.datetime.now().strftime(\"%Y년 %m월 %d일\")\n",
    "        # Save as PGN\n",
    "        pgn_filename = f\"{date_str}_PGN_LOG.txt\"\n",
    "        pgn_filepath = os.path.join(log_dir, pgn_filename)\n",
    "\n",
    "        game = chess.pgn.Game()\n",
    "\n",
    "        # Save the game result\n",
    "        reward_value = env._reward()\n",
    "        if reward_value == 1:\n",
    "            result = \"1-0\"  # 흰색 승리\n",
    "        elif reward_value == -1:\n",
    "            result = \"0-1\"  # 검은색 승리\n",
    "        elif reward_value == -0.5:\n",
    "            result = \"1/2-1/2\"  # 무승부\n",
    "        else:\n",
    "            result = \"*\"  # 게임 진행 중\n",
    "\n",
    "        game.headers[\"Result\"] = result\n",
    "        game.headers[\"Event\"] = \"BETAZERO_STUDY\"\n",
    "        game.headers[\"Site\"] = \"www.morokei.com/Deeplearning/Chess\"\n",
    "        game.headers[\"Date\"] = f\"{date_str}\"\n",
    "        game.headers[\"Round\"] = f\"{date_str}_EPISODE_{episode_number}\"\n",
    "        game.headers[\"White\"] = \"BETAZERO CARLSEN BOT\"\n",
    "        game.headers[\"Black\"] = \"BETAZERO HIKARU BOT\"\n",
    "\n",
    "        # Add moves to the game\n",
    "        board = env._board\n",
    "        move_list = board.move_stack\n",
    "        node = game\n",
    "        for move in move_list:\n",
    "            node = node.add_variation(move)\n",
    "\n",
    "        # Save the game to a file\n",
    "        with open(pgn_filepath, \"a\") as pgn_file:\n",
    "            pgn_file.write(str(game))\n",
    "            pgn_file.write(\"\\n\\n\")\n",
    "\n",
    "    def run(self):\n",
    "        scores1 = []\n",
    "        scores2 = []\n",
    "        scores_window1 = deque(maxlen=100)\n",
    "        scores_window2 = deque(maxlen=100)\n",
    "        eps = self.eps_start\n",
    "        episode_movies = []\n",
    "        for i_episode in range(1, self.num_episodes + 1):\n",
    "            state = self.env.reset()\n",
    "            state = encoder(state).numpy()\n",
    "            done = False\n",
    "            score = 0\n",
    "            moves = []\n",
    "\n",
    "            if i_episode % 100 == 0:  # Store the episode at every 100th episode\n",
    "                episode_movie = []\n",
    "\n",
    "            # Save model and buffer every 10000 episodes\n",
    "            if self.save_model_and_buffer and i_episode % 1000 == 0:\n",
    "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                model_name1 = f\"BETAZERO_CARLSEN_{timestamp}_EPISODE_{i_episode}.pth\"\n",
    "                model_name2 = f\"BETAZERO_HIKARU_{timestamp}_EPISODE_{i_episode}.pth\"\n",
    "                torch.save(self.dqn_agent1.local_net.state_dict(), f'{경로}/data/logs/models/{model_name1}')\n",
    "                torch.save(self.dqn_agent2.local_net.state_dict(), f'{경로}/data/logs/models/{model_name2}')\n",
    "\n",
    "                # Save Carlsen's replay buffer\n",
    "                buffer_name_carlsen = f\"{timestamp}_EPISODE_{i_episode}_BETAZERO_CARLSEN_Q_EXPERIENCES.pickle\"\n",
    "                with open(f\"{경로}/data/logs/Q_experiences(Buffers)/{buffer_name_carlsen}\", \"wb\") as file:\n",
    "                    pickle.dump(self.dqn_agent1.buffer, file)\n",
    "\n",
    "                # Save Hikaru's replay buffer\n",
    "                buffer_name_hikaru = f\"{timestamp}_EPISODE_{i_episode}_BETAZERO_HIKARU_Q_EXPERIENCES.pickle\"\n",
    "                with open(f\"{경로}/data/logs/Q_experiences(Buffers)/{buffer_name_hikaru}\", \"wb\") as file:\n",
    "                    pickle.dump(self.dqn_agent2.buffer, file)\n",
    "\n",
    "            # Swap agents every episode\n",
    "            if i_episode % 2 == 0:\n",
    "                current_agent = self.dqn_agent1\n",
    "                opponent_agent = self.dqn_agent2\n",
    "            else:\n",
    "                current_agent = self.dqn_agent2\n",
    "                opponent_agent = self.dqn_agent1\n",
    "\n",
    "            while not done:\n",
    "                action = current_agent.act(self.env, state, eps)\n",
    "                next_state, reward, done, info = self.env.step(outcome[action])\n",
    "\n",
    "                # If the move is illegal, the game does not update the state\n",
    "                if info['status'] != \"Illegal Move\":\n",
    "                    next_state = encoder(next_state).numpy()\n",
    "                else:\n",
    "                    reward = -1.0\n",
    "                    next_state = state\n",
    "\n",
    "                current_agent.step(self.env, state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                score += reward\n",
    "\n",
    "                if i_episode % 100 == 0:  # Store the moves only for the 100th episode\n",
    "                    moves.append((state, action, next_state, reward, done))\n",
    "\n",
    "                if done:\n",
    "                    self.dqn_agent1.trained = True\n",
    "                    break\n",
    "            \n",
    "            # Save and print the move for each episode\n",
    "            self.save_game_log(self.env, i_episode)\n",
    "            \n",
    "            # Swap agents\n",
    "            current_agent, opponent_agent = opponent_agent, current_agent\n",
    "\n",
    "            if i_episode % 2 == 0:\n",
    "                scores_window1.append(score)\n",
    "                scores1.append(score)\n",
    "            else:\n",
    "                scores_window2.append(score)\n",
    "                scores2.append(score)\n",
    "\n",
    "            eps = max(self.eps_end, self.eps_decay * eps)\n",
    "\n",
    "            if i_episode % 100 == 0:\n",
    "                print(f'\\r Episode {i_episode}\\tCarlsen Average Score: {np.mean(scores_window1):.2f}, Hikaru Average Score: {np.mean(scores_window2):.2f}')\n",
    "                print(f\"\\n Replay buffer size: {len(self.dqn_agent1.buffer)} ({sys.getsizeof(self.dqn_agent1.buffer.memory)/1024/1024:.3f} MB)\\n\")\n",
    "                episode_movie.append(moves)\n",
    "\n",
    "        return scores1, scores2, episode_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73f937",
   "metadata": {},
   "source": [
    "## OPTUNA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6aa50",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac0614fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HYPERPARAMETER_OPTIMIZING:\n",
    "    def __init__(self, dqn_agent1, dqn_agent2, env, num_episodes):\n",
    "        self.dqn_agent1 = dqn_agent1\n",
    "        self.dqn_agent2 = dqn_agent2\n",
    "        self.env = env\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "        gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
    "        tau = trial.suggest_uniform('tau', 0.001, 0.1)\n",
    "        buffer_size = int(trial.suggest_loguniform('buffer_size', 1e3, 1e7))\n",
    "        batch_size = 64\n",
    "        eps_start = 1.0\n",
    "        eps_end = 0.01\n",
    "        eps_decay = 0.995\n",
    "\n",
    "        cnn1 = CNN()\n",
    "        dqn_agent1 = DQN(cnn1, buffer_size=buffer_size, batch_size=batch_size, gamma=gamma,\n",
    "                         learning_rate=lr, tau=tau, device=device)\n",
    "\n",
    "        cnn2 = CNN()\n",
    "        dqn_agent2 = DQN(cnn2, buffer_size=buffer_size, batch_size=batch_size, gamma=gamma,\n",
    "                         learning_rate=lr, tau=tau, device=device)\n",
    "\n",
    "        hyperparameter_optimization_num_episodes = self.num_episodes\n",
    "\n",
    "        game_runner = RunGame(dqn_agent1, dqn_agent2, env, num_episodes, [])\n",
    "        scores1, scores2, episode_movies = game_runner.run()\n",
    "        return np.mean(scores1)\n",
    "\n",
    "\n",
    "    def optimize(self, n_trials):\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self.objective, n_trials=n_trials)\n",
    "\n",
    "        print('Number of finished trials:', len(study.trials))\n",
    "        print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb89e6",
   "metadata": {},
   "source": [
    "## Model Save & Load 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc824b",
   "metadata": {},
   "source": [
    "### Save Model 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aac897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(dqn_agent):\n",
    "    if not dqn_agent.trained:\n",
    "        print(\"저장할 모델이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_filename = f\"BETAZERO_{timestamp}_SAVED_EPISODE.pth\"\n",
    "    torch.save(dqn_agent.local_net.state_dict(), f'{경로}/data/logs/models/{model_filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2745f",
   "metadata": {},
   "source": [
    "### Load Model 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd9e4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadModel:\n",
    "    def __init__(self, path):\n",
    "        # Find the most recent model and buffer files\n",
    "        model_files = os.listdir(f\"{path}/data/logs/models/\")\n",
    "        buffer_files = os.listdir(f\"{path}/data/logs/Q_experiences(Buffers)/\")\n",
    "\n",
    "        carlsen_model_files = [file for file in model_files if \"BETAZERO_CARLSEN\" in file]\n",
    "        hikaru_model_files = [file for file in model_files if \"BETAZERO_HIKARU\" in file]\n",
    "\n",
    "        carlsen_buffer_files = [file for file in buffer_files if \"BETAZERO_CARLSEN\" in file]\n",
    "        hikaru_buffer_files = [file for file in buffer_files if \"BETAZERO_HIKARU\" in file]\n",
    "\n",
    "        # Extract episode numbers from the file names\n",
    "        carlsen_model_episodes = [int(re.search(\"EPISODE_(\\d+)\", file).group(1)) for file in carlsen_model_files]\n",
    "        hikaru_model_episodes = [int(re.search(\"EPISODE_(\\d+)\", file).group(1)) for file in hikaru_model_files]\n",
    "\n",
    "        carlsen_buffer_episodes = [int(re.search(\"EPISODE_(\\d+)\", file).group(1)) for file in carlsen_buffer_files]\n",
    "        hikaru_buffer_episodes = [int(re.search(\"EPISODE_(\\d+)\", file).group(1)) for file in hikaru_buffer_files]\n",
    "\n",
    "        # Find the most recent episodes\n",
    "        carlsen_most_recent_episode = max(carlsen_model_episodes)\n",
    "        hikaru_most_recent_episode = max(hikaru_model_episodes)\n",
    "\n",
    "        carlsen_model_file = carlsen_model_files[carlsen_model_episodes.index(carlsen_most_recent_episode)]\n",
    "        hikaru_model_file = hikaru_model_files[hikaru_model_episodes.index(hikaru_most_recent_episode)]\n",
    "\n",
    "        carlsen_buffer_file = carlsen_buffer_files[carlsen_buffer_episodes.index(carlsen_most_recent_episode)]\n",
    "        hikaru_buffer_file = hikaru_buffer_files[hikaru_buffer_episodes.index(hikaru_most_recent_episode)]\n",
    "\n",
    "        # Load the most recent models and buffers\n",
    "        self._load_model_and_buffer(carlsen_model_file, carlsen_buffer_file, 1)\n",
    "        self._load_model_and_buffer(hikaru_model_file, hikaru_buffer_file, 2)\n",
    "\n",
    "    def _load_model_and_buffer(self, model_filename, buffer_filename, model_number):\n",
    "        # Load the model\n",
    "        model = CNN()\n",
    "        model.load_state_dict(torch.load(f'{경로}/data/logs/models/{model_filename}'))\n",
    "        model.to(device)  # GPU에서 실행할 경우 필요\n",
    "        model.eval()  # 추론 모드로 전환\n",
    "\n",
    "        # Load the replay buffer\n",
    "        with open(f\"{경로}/data/logs/Q_experiences(Buffers)/{buffer_filename}\", \"rb\") as file:\n",
    "            buffer = pickle.load(file)\n",
    "\n",
    "        if model_number == 1:\n",
    "            self.model1 = model\n",
    "            self.buffer1 = buffer\n",
    "        else:\n",
    "            self.model2 = model\n",
    "            self.buffer2 = buffer\n",
    "    def infer_q_values(self, state, model_number):\n",
    "        state_tensor = torch.from_numpy(state).float().to(device).view(1, 14, 8, 8)\n",
    "        if model_number == 1:\n",
    "            q_values = self.model1(state_tensor)\n",
    "        else:\n",
    "            q_values = self.model2(state_tensor)\n",
    "        return q_values\n",
    "\n",
    "    def select_best_action(self, state, model_number):\n",
    "        q_values = self.infer_q_values(state, model_number)\n",
    "        best_action = np.argmax(q_values.cpu().data.numpy())\n",
    "        return best_action\n",
    "\n",
    "    def evaluate(self, env, num_episodes):\n",
    "        total_rewards = []\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            state = env.reset()\n",
    "            state = encoder(state).numpy()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                best_action = self.select_best_action(state)\n",
    "                next_state, reward, done, info = env.step(outcome[best_action])\n",
    "\n",
    "                if info['status'] != \"Illegal Move\":\n",
    "                    next_state = encoder(next_state).numpy()\n",
    "\n",
    "                episode_reward += reward\n",
    "                state = next_state\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            total_rewards.append(episode_reward)\n",
    "\n",
    "        return total_rewards\n",
    "\n",
    "    def interactive_menu(self, env):\n",
    "        while True:\n",
    "            print(\"\\n1: Q 값 추론\")\n",
    "            print(\"2: 최적의 행동 선택\")\n",
    "            print(\"3: 평가하기\")\n",
    "            print(\"4: 추가 학습\")\n",
    "            print(\"0: 종료\")\n",
    "            option = input(\"Enter the option number (1, 2, 3, 4, or 0): \")\n",
    "            \n",
    "            if option == \"1\":\n",
    "                model_number = int(input(\"모델 번호를 선택하세요 (1: CARLSEN, 2: HIKARU): \"))\n",
    "                sample_state = env.reset()\n",
    "                encoded_state = encoder(sample_state).numpy()\n",
    "                q_values = self.infer_q_values(encoded_state, model_number)\n",
    "                print(\"Q values:\", q_values)\n",
    "            elif option == \"2\":\n",
    "                model_number = int(input(\"모델 번호를 선택하세요 (1: CARLSEN, 2: HIKARU): \"))\n",
    "                sample_state = env.reset()\n",
    "                encoded_state = encoder(sample_state).numpy()\n",
    "                best_action = self.select_best_action(encoded_state, model_number)\n",
    "                print(\"Best action:\", best_action)\n",
    "            elif option == \"3\":\n",
    "                num_evaluation_episodes = 100\n",
    "                evaluation_rewards = self.evaluate(env, num_evaluation_episodes)\n",
    "                average_reward = np.mean(evaluation_rewards)\n",
    "                print(f\"모델의 평균 보상: {average_reward}\")\n",
    "            elif option == \"4\":\n",
    "                cnn1 = CNN()\n",
    "                cnn2 = CNN()\n",
    "                dqn_agent1 = DQN(cnn1, device=device)\n",
    "                dqn_agent2 = DQN(cnn2, device=device)\n",
    "                num_episodes = 1000000\n",
    "                \n",
    "                game_runner = RunGame(dqn_agent1, dqn_agent2, env, num_episodes, [])\n",
    "                scores1, scores2, episode_movies = game_runner.run()\n",
    "            \n",
    "                \n",
    "            elif option == \"0\":\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter 1, 2, 3, 4, or 0.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37776074",
   "metadata": {},
   "source": [
    "## MOVIE 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32278db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3.dev8 (SDL 2.0.22, Python 3.10.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "def betazero_vs_betazero_movie(episodes, index):\n",
    "    pygame.init()\n",
    "    pygame.mixer.init()\n",
    "    moves = episodes[index]\n",
    "\n",
    "    # Display settings\n",
    "    WIDTH, HEIGHT = 800, 800\n",
    "    BOARD_SIZE = 8\n",
    "    SQ_SIZE = WIDTH // BOARD_SIZE\n",
    "\n",
    "    # Colors\n",
    "    WHITE = (216, 182, 142)\n",
    "    BLACK = (101, 67, 33)\n",
    "    GREY = (128, 128, 128)\n",
    "\n",
    "    # Initialize mixer and load music\n",
    "    music_files = [\n",
    "        \"\"+경로+\"/data/UI/bgm/Jazz Music #1.mp3\",\n",
    "        \"\"+경로+\"/data/UI/bgm/Jazz Music #2.mp3\",\n",
    "        \"\"+경로+\"/data/UI/bgm/Jazz Music #3.mp3\",\n",
    "        \"\"+경로+\"/data/UI/bgm/Jazz Music #4.mp3\",\n",
    "        \"\"+경로+\"/data/UI/bgm/Jazz Music #5.mp3\",\n",
    "    ]\n",
    "    MUSIC_ENDEVENT = pygame.USEREVENT + 1\n",
    "    pygame.mixer.music.set_endevent(MUSIC_ENDEVENT)\n",
    "    current_music_index = random.randint(0, 2)\n",
    "    pygame.mixer.music.load(music_files[current_music_index])\n",
    "    pygame.mixer.music.set_volume(0.2)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    def draw_board(screen, board):\n",
    "        for r in range(BOARD_SIZE):\n",
    "            for c in range(BOARD_SIZE):\n",
    "                color = WHITE if (r + c) % 2 == 0 else BLACK\n",
    "                pygame.draw.rect(screen, color, (c * SQ_SIZE, r * SQ_SIZE, SQ_SIZE, SQ_SIZE))\n",
    "                piece = board.piece_at((BOARD_SIZE - 1 - r) * BOARD_SIZE + c)\n",
    "                if piece:\n",
    "                    screen.blit(PIECES[str(piece)], (c * SQ_SIZE, r * SQ_SIZE))\n",
    "\n",
    "    def main(episodes, index):\n",
    "        screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "        pygame.display.set_caption(\"Betazero VS Betazero Movie\")\n",
    "\n",
    "        global PIECES\n",
    "        PIECES = {}\n",
    "        piece_path = \"\"+경로+\"/data/UI/기물 이미지\"\n",
    "        for piece_type in chess.PIECE_TYPES:\n",
    "            for color in [chess.WHITE, chess.BLACK]:\n",
    "                piece = chess.Piece(piece_type, color)\n",
    "                name = f\"Chess_{piece.symbol()}{'w' if color else 'd'}.png\"\n",
    "                filepath = os.path.join(piece_path, name)\n",
    "                image = pygame.image.load(filepath).convert_alpha()\n",
    "                image = pygame.transform.scale(image, (SQ_SIZE, SQ_SIZE))\n",
    "                PIECES[str(piece)] = image\n",
    "\n",
    "        moves = episodes[index]\n",
    "        board = chess.Board()\n",
    "        for move in moves:\n",
    "            board.push(move)\n",
    "            draw_board(screen, board)\n",
    "            pygame.display.update()\n",
    "            pygame.time.delay(500)\n",
    "\n",
    "        pygame.time.delay(2000)\n",
    "        pygame.quit()\n",
    "\n",
    "    main(episodes, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94ab92",
   "metadata": {},
   "source": [
    "# 실행 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b56c950f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: 모델 만들기\n",
      "2: 하이퍼 파라미터 최적화\n",
      "3: 모델 저장하기\n",
      "4: 모델 불러오기\n",
      "0: 종료\n",
      "Enter the number (1, 2, 3, 4, or 0): 1\n",
      "\n",
      "모델 학습을 시작합니다.\n",
      "1...\n",
      "\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Temp\\ipykernel_14628\\400420255.py\", line 62, in <module>\n",
      "    실행()\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Temp\\ipykernel_14628\\400420255.py\", line 44, in 실행\n",
      "    scores1, scores2, episode_movies = game_runner.run()\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Temp\\ipykernel_14628\\1433714735.py\", line 108, in run\n",
      "    current_agent.step(self.env, state, action, reward, next_state, done)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Temp\\ipykernel_14628\\989182782.py\", line 18, in step\n",
      "    self.learn(experiences)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Temp\\ipykernel_14628\\989182782.py\", line 24, in learn\n",
      "    Q_targets_next = self.target_net(next_states).detach().max(1)[0].unsqueeze(1)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Temp\\ipykernel_14628\\3997375386.py\", line 21, in forward\n",
      "    x = torch.cat(conv_outputs, dim=1)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 274.00 MiB (GPU 0; 8.00 GiB total capacity; 807.93 MiB already allocated; 0 bytes free; 964.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 793, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 848, in get_records\n",
      "    return list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 323, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 247, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 275, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, lines)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 285, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 97, in __init__\n",
      "    self.asttokens()\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 387, in asttokens\n",
      "    return ASTTokens(\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\asttokens\\asttokens.py\", line 67, in __init__\n",
      "    self._tokens = list(self._generate_tokens(source_text))\n",
      "  File \"C:\\Users\\ojs53\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\asttokens\\asttokens.py\", line 97, in _generate_tokens\n",
      "    original_tokens = tokenize.generate_tokens(cast(Callable[[], str], io.StringIO(text).readline))\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "def 실행():\n",
    "    while True:\n",
    "        print(\"\\n1: 모델 만들기\")\n",
    "        print(\"2: 하이퍼 파라미터 최적화\")\n",
    "        print(\"3: 모델 저장하기\")\n",
    "        print(\"4: 모델 불러오기\")\n",
    "        print(\"0: 종료\")\n",
    "\n",
    "        choice = input(\"Enter the number (1, 2, 3, 4, or 0): \")\n",
    "        \n",
    "        cnn1 = CNN()\n",
    "        cnn2 = CNN()\n",
    "        dqn_agent1 = DQN(cnn1, device=device)\n",
    "        dqn_agent2 = DQN(cnn2, device=device)\n",
    "\n",
    "        if choice == \"1\":\n",
    "            print(\"\\n모델 학습을 시작합니다.\")\n",
    "        elif choice == \"2\":\n",
    "            print(\"\\n하이퍼 파라미터 최적화를 시작합니다.\")\n",
    "        elif choice == \"3\":\n",
    "            print(\"\\n모델을 저장합니다.\")\n",
    "        elif choice == \"4\":\n",
    "            print(\"\\n모델을 불러옵니다.\")\n",
    "        elif choice == \"0\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 1, 2, 3, 4, or 0.\")\n",
    "            continue\n",
    "\n",
    "        for i in range(3, 0, -1):\n",
    "            sys.stdout.write(f\"\\r{i}...\")\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(1)\n",
    "\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            episode_movies = []\n",
    "            num_episodes = 100000\n",
    "            \n",
    "            game_runner = RunGame(dqn_agent1, dqn_agent2, env, num_episodes, [])\n",
    "            scores1, scores2, episode_movies = game_runner.run()\n",
    "            # Play the movies\n",
    "            for idx, episode in enumerate(episode_movies):\n",
    "                betazero_vs_betazero_movie(episode, idx)\n",
    "\n",
    "        elif choice == \"2\":\n",
    "            num_episodes = 20000\n",
    "            opt = HYPERPARAMETER_OPTIMIZING(dqn_agent1, dqn_agent2, env, num_episodes)\n",
    "            \n",
    "            opt.optimize(n_trials=10)\n",
    "        elif choice == \"3\":\n",
    "            save_model(dqn_agent1)\n",
    "        elif choice == \"4\":\n",
    "            model_filename = input(\"Enter the model filename (without .pth extension): \")\n",
    "            loaded_model = LoadModel(model_filename)\n",
    "            loaded_model.interactive_menu(env)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    실행()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env._reward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b4941",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26c727",
   "metadata": {},
   "source": [
    "### HUMAN VS BETAZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90825998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def 베타제로랑한판():\n",
    "    import pygame\n",
    "    import chess\n",
    "    import chess.engine\n",
    "    import chess.svg\n",
    "    import os\n",
    "    import sys\n",
    "    import io\n",
    "    from reportlab.graphics import renderPM\n",
    "    from svglib.svglib import svg2rlg\n",
    "    \n",
    "    def load_latest_betazero_model(model_directory):\n",
    "        model_files = glob.glob(os.path.join(model_directory, \"BETAZERO_CARLSEN_*.pth\"))\n",
    "        latest_model_file = max(model_files, key=os.path.getctime)\n",
    "        print(latest_model_file)\n",
    "        return latest_model_file\n",
    "\n",
    "    # Load BETAZERO model\n",
    "    model_directory = \"\"+경로+\"/data/logs/models\"\n",
    "    model_path = load_latest_betazero_model(model_directory)\n",
    "\n",
    "    # Load BETAZERO model\n",
    "    cnn = CNN()\n",
    "    betazero_agent = DQN(cnn)\n",
    "    betazero_agent.local_net.load_state_dict(torch.load(model_path))\n",
    "    betazero_agent.local_net.eval()\n",
    "\n",
    "\n",
    "    def betazero_action(state, agent):\n",
    "        state_tensor = encoder(state).unsqueeze(0).squeeze(1).to(agent.device)\n",
    "        action_values = agent.local_net(state_tensor)\n",
    "        _, action = torch.max(action_values, dim=1)\n",
    "        return action.item()\n",
    "\n",
    "\n",
    "    pygame.init()\n",
    "\n",
    "    # Display settings\n",
    "    WIDTH, HEIGHT = 800, 800\n",
    "    BOARD_SIZE = 8\n",
    "    SQ_SIZE = WIDTH // BOARD_SIZE\n",
    "\n",
    "    # Colors\n",
    "    WHITE = (216, 182, 142)\n",
    "    BLACK = (101, 67, 33)\n",
    "    GREY = (128, 128, 128)\n",
    "\n",
    "    # 탭 화면\n",
    "    TAB_WIDTH = 400\n",
    "    TAB_HEIGHT = HEIGHT\n",
    "    TAB_X = WIDTH\n",
    "    TAB_Y = 0\n",
    "\n",
    "    def svg_to_surface(svg_data, size):\n",
    "        svg_io = io.StringIO(svg_data)\n",
    "        svg_image = svg2rlg(svg_io)\n",
    "        buffer = io.BytesIO()\n",
    "        renderPM.drawToFile(svg_image, buffer, fmt=\"PNG\")\n",
    "        buffer.seek(0)\n",
    "        return pygame.image.load(io.BytesIO(buffer.read()))\n",
    "\n",
    "    def draw_board(screen, board, moves, selected, player_color, row, col):\n",
    "        for r in range(BOARD_SIZE):\n",
    "            for c in range(BOARD_SIZE):\n",
    "                color = WHITE if (r + c) % 2 == 0 else BLACK\n",
    "                pygame.draw.rect(screen, color, (c * SQ_SIZE, r * SQ_SIZE, SQ_SIZE, SQ_SIZE))\n",
    "                piece = board.piece_at((BOARD_SIZE - 1 - r) * BOARD_SIZE + c)\n",
    "                if piece:\n",
    "                    screen.blit(PIECES[str(piece)], (c * SQ_SIZE, r * SQ_SIZE))\n",
    "        if selected is not None:\n",
    "            r, c = divmod(selected, BOARD_SIZE)\n",
    "            pygame.draw.rect(screen, (255, 0, 0), (c * SQ_SIZE, (BOARD_SIZE - 1 - r) * SQ_SIZE, SQ_SIZE, SQ_SIZE), 5)\n",
    "            for move in moves:\n",
    "                r, c = divmod(move.to_square, BOARD_SIZE)\n",
    "                pygame.draw.circle(screen, GREY, (c * SQ_SIZE + SQ_SIZE // 2, (BOARD_SIZE - 1 - r) * SQ_SIZE + SQ_SIZE // 2),\n",
    "                   SQ_SIZE // 4)\n",
    "    def main():\n",
    "        screen = pygame.display.set_mode((WIDTH + TAB_WIDTH, HEIGHT))\n",
    "        tab_surface = pygame.Surface((TAB_WIDTH, TAB_HEIGHT))\n",
    "        tab_surface.fill((0, 0, 0))\n",
    "\n",
    "        #pygame.mixer.music.load(''+경로+'/data/UI/bgm/what am i to say _ sum 41.mp3')\n",
    "        #pygame.mixer.music.set_volume(0.2)\n",
    "        #pygame.mixer.music.play(-1)\n",
    "        FONT = pygame.font.SysFont(\"arial\", 32)\n",
    "        pygame.display.set_caption(\"모로케이의 얼렁뚱땅 체스한판\")\n",
    "\n",
    "        global PIECES\n",
    "        PIECES = {}\n",
    "        piece_path = \"\"+경로+\"/data/UI/기물 이미지\"\n",
    "        for piece_type in chess.PIECE_TYPES:\n",
    "            for color in [chess.WHITE, chess.BLACK]:\n",
    "                piece = chess.Piece(piece_type, color)\n",
    "                name = f\"Chess_{piece.symbol()}{'w' if color else 'd'}.png\"\n",
    "                filepath = os.path.join(piece_path, name)\n",
    "                image = pygame.image.load(filepath).convert_alpha()\n",
    "                image = pygame.transform.scale(image, (SQ_SIZE, SQ_SIZE))\n",
    "                PIECES[str(piece)] = image\n",
    "\n",
    "        board = chess.Board()\n",
    "        player_color = chess.WHITE\n",
    "\n",
    "        clock = pygame.time.Clock()\n",
    "\n",
    "        selected = None\n",
    "        moves = []  # possible moves for the selected piece\n",
    "        game_running = True\n",
    "        game_over = False\n",
    "        row, col = None, None\n",
    "        while game_running:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    game_running = False\n",
    "                elif not game_over:\n",
    "                    if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                        # get the square clicked by the user\n",
    "                        x, y = pygame.mouse.get_pos()\n",
    "                        col = x // SQ_SIZE\n",
    "                        row = y // SQ_SIZE\n",
    "                        # select a piece\n",
    "                        piece = board.piece_at((BOARD_SIZE - 1 - row) * BOARD_SIZE + col)\n",
    "                        if piece:\n",
    "                            if selected == None and piece.color == player_color:\n",
    "                                selected = (BOARD_SIZE - 1 - row) * BOARD_SIZE + col\n",
    "                                from_mask = chess.BB_SQUARES[selected]\n",
    "                                moves = list(board.generate_legal_moves(from_mask=from_mask))\n",
    "                    elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                        if selected != None:\n",
    "                            # get the ending square\n",
    "                            x, y = pygame.mouse.get_pos()\n",
    "                            col = x // SQ_SIZE\n",
    "                            row = y // SQ_SIZE\n",
    "                            dest = (BOARD_SIZE - 1 - row) * BOARD_SIZE + col\n",
    "\n",
    "                            # attempt to make the move\n",
    "                            move = chess.Move(selected, dest)\n",
    "                            if move in moves:\n",
    "                                board.push(move)\n",
    "                                print(board)\n",
    "                                # get the betazero's move\n",
    "                                betazero_move = betazero_action(board, betazero_agent)\n",
    "                                print(\"Betazero move in main:\", betazero_move)\n",
    "                                move = index_to_move(betazero_move)\n",
    "                                print(\"Converted move:\", move)\n",
    "                                print(board.is_game_over())\n",
    "                                if move in board.legal_moves:\n",
    "                                    board.push(move)\n",
    "                                else:\n",
    "                                    print(f\"{move} is not a legal move.\")\n",
    "\n",
    "                            # reset the selected piece\n",
    "                            selected = None\n",
    "                            moves = []\n",
    "\n",
    "            draw_board(screen, board, moves, selected, player_color, col, row)\n",
    "            screen.blit(tab_surface, (TAB_X, TAB_Y))\n",
    "\n",
    "            # check for endgame\n",
    "            if board.is_game_over():\n",
    "                game_over = True  # Set game_over flag to True\n",
    "                result = board.result()\n",
    "                if result == \"0-1\":\n",
    "                    text = FONT.render(\"You lose\", True, (255, 0, 0))\n",
    "                elif result == \"1-0\":\n",
    "                    text = FONT.render(\"You win\", True, (0, 255, 0))\n",
    "                else:\n",
    "                    text = FONT.render(\"Draw\", True, (128, 128, 128))\n",
    "\n",
    "                tab_surface.blit(text, (TAB_WIDTH // 2 - text.get_width() // 2, TAB_HEIGHT // 2 - text.get_height() // 2))\n",
    "                pygame.display.update()\n",
    "\n",
    "            pygame.display.update()\n",
    "            clock.tick(60)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad4ddb",
   "metadata": {},
   "source": [
    "### STOCKFISH VS BETAZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play against Stockfish\n",
    "def betazero_vs_stockfish():\n",
    "    import chess.engine\n",
    "\n",
    "    engine = chess.engine.SimpleEngine.popen_uci(\"\"+경로+\"/data/UI/stockfish/stockfish-windows-2022-x86-64-avx2.exe\")\n",
    "\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    while not done:\n",
    "        # Get action from the agent\n",
    "        action = dqn_agent.act(observation)\n",
    "\n",
    "        # Play the action\n",
    "        fen = env.observation_to_fen(observation)\n",
    "        board = chess.Board(fen)\n",
    "        engine_move = engine.play(board, chess.engine.Limit(time=2.0))\n",
    "        move = gym_chess.utils.uci_to_action(str(engine_move.move), board.turn)\n",
    "        observation, reward, done, info = env.step(move)\n",
    "\n",
    "        # Render the board\n",
    "        env.render()\n",
    "\n",
    "        if done:\n",
    "            # Print the game result\n",
    "            print(\"Game over: \", info[\"result\"])\n",
    "\n",
    "    engine.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f179a0",
   "metadata": {},
   "source": [
    "### STOCKFISH VS HUMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0c26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def 스탁피시랑한판():\n",
    "    import pygame\n",
    "    import chess\n",
    "    import chess.engine\n",
    "    import chess.svg\n",
    "    import os\n",
    "    import sys\n",
    "    import io\n",
    "    from reportlab.graphics import renderPM\n",
    "    from svglib.svglib import svg2rlg\n",
    "\n",
    "    pygame.init()\n",
    "\n",
    "    # Display settings\n",
    "    WIDTH, HEIGHT = 800, 800\n",
    "    BOARD_SIZE = 8\n",
    "    SQ_SIZE = WIDTH // BOARD_SIZE\n",
    "\n",
    "    # Colors\n",
    "    WHITE = (216, 182, 142)\n",
    "    BLACK = (101, 67, 33)\n",
    "    GREY = (128, 128, 128)\n",
    "\n",
    "    # 탭 화면\n",
    "    TAB_WIDTH = 400\n",
    "    TAB_HEIGHT = HEIGHT\n",
    "    TAB_X = WIDTH\n",
    "    TAB_Y = 0\n",
    "\n",
    "    def svg_to_surface(svg_data, size):\n",
    "        svg_io = io.StringIO(svg_data)\n",
    "        svg_image = svg2rlg(svg_io)\n",
    "        buffer = io.BytesIO()\n",
    "        renderPM.drawToFile(svg_image, buffer, fmt=\"PNG\")\n",
    "        buffer.seek(0)\n",
    "        return pygame.image.load(io.BytesIO(buffer.read()))\n",
    "\n",
    "    def draw_board(screen, board, moves, selected, player_color, row, col):\n",
    "        for r in range(BOARD_SIZE):\n",
    "            for c in range(BOARD_SIZE):\n",
    "                color = WHITE if (r + c) % 2 == 0 else BLACK\n",
    "                pygame.draw.rect(screen, color, (c * SQ_SIZE, r * SQ_SIZE, SQ_SIZE, SQ_SIZE))\n",
    "                piece = board.piece_at((BOARD_SIZE - 1 - r) * BOARD_SIZE + c)\n",
    "                if piece:\n",
    "                    screen.blit(PIECES[str(piece)], (c * SQ_SIZE, r * SQ_SIZE))\n",
    "        if selected is not None:\n",
    "            r, c = divmod(selected, BOARD_SIZE)\n",
    "            pygame.draw.rect(screen, (255, 0, 0), (c * SQ_SIZE, (BOARD_SIZE - 1 - r) * SQ_SIZE, SQ_SIZE, SQ_SIZE), 5)\n",
    "            for move in moves:\n",
    "                r, c = divmod(move.to_square, BOARD_SIZE)\n",
    "                pygame.draw.circle(screen, GREY, (c * SQ_SIZE + SQ_SIZE // 2, (BOARD_SIZE - 1 - r) * SQ_SIZE + SQ_SIZE // 2),\n",
    "                                   SQ_SIZE // 4)\n",
    "\n",
    "    def main():\n",
    "        screen = pygame.display.set_mode((WIDTH + TAB_WIDTH, HEIGHT))\n",
    "        tab_surface = pygame.Surface((TAB_WIDTH, TAB_HEIGHT))\n",
    "        tab_surface.fill((0, 0, 0))\n",
    "\n",
    "        pygame.mixer.music.load(\"\"+경로+\"/data/UI/bgm/what am i to say _ sum 41.mp3\")\n",
    "        pygame.mixer.music.set_volume(0.2)\n",
    "        pygame.mixer.music.play(-1)\n",
    "        FONT = pygame.font.SysFont(\"arial\", 32)\n",
    "        pygame.display.set_caption(\"모로케이의 얼렁뚱땅 체스한판\")\n",
    "\n",
    "        global PIECES\n",
    "        PIECES = {}\n",
    "        piece_path = \"\"+경로+\"/data/UI/기물 이미지\"\n",
    "        for piece_type in chess.PIECE_TYPES:\n",
    "            for color in [chess.WHITE, chess.BLACK]:\n",
    "                piece = chess.Piece(piece_type, color)\n",
    "                name = f\"Chess_{piece.symbol()}{'w' if color else 'd'}.png\"\n",
    "                filepath = os.path.join(piece_path, name)\n",
    "                image = pygame.image.load(filepath).convert_alpha()\n",
    "                image = pygame.transform.scale(image, (SQ_SIZE, SQ_SIZE))\n",
    "                PIECES[str(piece)] = image\n",
    "\n",
    "        board = chess.Board()\n",
    "        engine = chess.engine.SimpleEngine.popen_uci(\"\"+경로+\"/data/UI/stockfish/stockfish-windows-2022-x86-64-avx2.exe\")\n",
    "        player_color = chess.WHITE\n",
    "\n",
    "        clock = pygame.time.Clock()\n",
    "\n",
    "        selected = None\n",
    "        moves = []  # possible moves for the selected piece\n",
    "        game_running = True\n",
    "        game_over = False\n",
    "        row, col = None, None\n",
    "        while game_running:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    game_running = False\n",
    "                elif not game_over:\n",
    "                    if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                        # get the square clicked by the user\n",
    "                        x,y = pygame.mouse.get_pos()\n",
    "                        col = x // SQ_SIZE\n",
    "                        row = y // SQ_SIZE\n",
    "                        # select a piece\n",
    "                        piece = board.piece_at((BOARD_SIZE - 1 - row) * BOARD_SIZE + col)\n",
    "                        if piece:\n",
    "                            if selected == None and piece.color == player_color:\n",
    "                                selected = (BOARD_SIZE - 1 - row) * BOARD_SIZE + col\n",
    "                                from_mask = chess.BB_SQUARES[selected]\n",
    "                                moves = list(board.generate_legal_moves(from_mask=from_mask))\n",
    "                    elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                        if selected != None:\n",
    "                            # get the ending square\n",
    "                            x,y = pygame.mouse.get_pos()\n",
    "                            col = x // SQ_SIZE\n",
    "                            row = y // SQ_SIZE\n",
    "                            dest = (BOARD_SIZE - 1 - row) * BOARD_SIZE + col\n",
    "\n",
    "                            # attempt to make the move\n",
    "                            move = chess.Move(selected, dest)\n",
    "                            if move in moves:\n",
    "                                board.push(move)\n",
    "\n",
    "                                # get the engine's move\n",
    "                                result = engine.play(board, chess.engine.Limit(time=0.1))\n",
    "                                board.push(result.move)\n",
    "\n",
    "                            # reset the selected piece\n",
    "                            selected = None\n",
    "                            moves = []\n",
    "\n",
    "            draw_board(screen, board, moves, selected, player_color, col, row)\n",
    "            screen.blit(tab_surface, (TAB_X, TAB_Y))\n",
    "\n",
    "            # check for endgame\n",
    "            if board.is_game_over():\n",
    "                game_over = True  # Set game_over flag to True\n",
    "                result = board.result()\n",
    "                if result == \"0-1\":\n",
    "                    text = FONT.render(\"You lose\", True, (255, 0, 0))\n",
    "                elif result == \"1-0\":\n",
    "                    text = FONT.render(\"You win\", True, (0, 255, 0))\n",
    "                else:\n",
    "                    text = FONT.render(\"Draw\", True, (128, 128, 128))\n",
    "\n",
    "                tab_surface.blit(text, (TAB_WIDTH // 2 - text.get_width() // 2, TAB_HEIGHT // 2 - text.get_height() // 2))\n",
    "                pygame.display.update()\n",
    "\n",
    "            pygame.display.update()\n",
    "            clock.tick(60)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5b66b",
   "metadata": {},
   "source": [
    "### BETAZERO VS BETAZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67445e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5daba2e6",
   "metadata": {},
   "source": [
    "### STOCKFISH VS STOCKFISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d16f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stockfish_vs_stockfish():\n",
    "    import pygame ; import chess  ; import chess.engine  ; import os  ;import sys\n",
    "    import io ; import random ; import datetime ; import time\n",
    "    인풋받기 = int(input(\"몇게임돌릴래? \\n\"))\n",
    "    time.sleep(3)\n",
    "    pygame.init()\n",
    "    \n",
    "    # Display settings\n",
    "    WIDTH, HEIGHT = 800, 800\n",
    "    BOARD_SIZE = 8\n",
    "    SQ_SIZE = WIDTH // BOARD_SIZE\n",
    "    WHITE = (216, 182, 142)\n",
    "    BLACK = (101, 67, 33)\n",
    "    GREY = (128, 128, 128)\n",
    "    TAB_WIDTH = 400\n",
    "    TAB_HEIGHT = HEIGHT\n",
    "    TAB_X = WIDTH\n",
    "    TAB_Y = 0\n",
    "\n",
    "    pygame.display.set_caption(\"Stockfish vs Stockfish\")\n",
    "    screen = pygame.display.set_mode((WIDTH + TAB_WIDTH, HEIGHT))\n",
    "\n",
    "    # Initialize mixer and load music\n",
    "    pygame.mixer.init()\n",
    "    music_files = [\n",
    "        \"\"+경로+\"/data/UI/bgm/2pac california love.mp3\",\n",
    "        \"\"+경로+\"/data/UI/bgm/all eyes on me _ 2pac.mp3\",\n",
    "        \"\"+경로+\"/data/UI/bgm/dear mama - 2pac.mp3\"\n",
    "    ]\n",
    "    MUSIC_ENDEVENT = pygame.USEREVENT + 1\n",
    "    pygame.mixer.music.set_endevent(MUSIC_ENDEVENT)\n",
    "    current_music_index = random.randint(0, 2)\n",
    "    pygame.mixer.music.load(music_files[current_music_index])\n",
    "    pygame.mixer.music.set_volume(0.2)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    FONT = pygame.font.SysFont(\"arial\", 32)\n",
    "    tab_surface = pygame.Surface((TAB_WIDTH, TAB_HEIGHT))\n",
    "    tab_surface.fill((0, 0, 0))\n",
    "\n",
    "    global PIECES\n",
    "    PIECES = {}\n",
    "    piece_path = \"\"+경로+\"/data/UI/기물 이미지\"\n",
    "    for piece_type in chess.PIECE_TYPES:\n",
    "        for color in [chess.WHITE, chess.BLACK]:\n",
    "            piece = chess.Piece(piece_type, color)\n",
    "            name = f\"Chess_{piece.symbol()}{'w' if color else 'd'}.png\"\n",
    "            filepath = os.path.join(piece_path, name)\n",
    "            image = pygame.image.load(filepath).convert_alpha()\n",
    "            image = pygame.transform.scale(image, (SQ_SIZE, SQ_SIZE))\n",
    "            PIECES[str(piece)] = image\n",
    "\n",
    "    board = chess.Board()\n",
    "    engine = chess.engine.SimpleEngine.popen_uci(\"\"+경로+\"/data/UI/stockfish/stockfish-windows-2022-x86-64-avx2.exe\")\n",
    "\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    total_games = 인풋받기\n",
    "    white_wins = 0\n",
    "    black_wins = 0\n",
    "    draws = 0\n",
    "    game_over = False\n",
    "    \n",
    "    for game in range(total_games):\n",
    "        board = chess.Board()\n",
    "        game_running = True\n",
    "        game_over = False\n",
    "        pygame.time.delay(3000)\n",
    "        while game_running:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    game_running = False\n",
    "                elif event.type == MUSIC_ENDEVENT:\n",
    "                    current_music_index = (current_music_index + 1) % len(music_files)\n",
    "                    pygame.mixer.music.load(music_files[current_music_index])\n",
    "                    pygame.mixer.music.play()\n",
    "\n",
    "            if not game_over:\n",
    "                result = engine.play(board, chess.engine.Limit(time=0.1))\n",
    "                if result.move is not None:\n",
    "                    board.push(result.move)\n",
    "\n",
    "                for r in range(BOARD_SIZE):\n",
    "                    for c in range(BOARD_SIZE):\n",
    "                        color = WHITE if (r + c) % 2 == 0 else BLACK\n",
    "                        pygame.draw.rect(screen, color, (c * SQ_SIZE, r * SQ_SIZE, SQ_SIZE, SQ_SIZE))\n",
    "                        piece = board.piece_at((BOARD_SIZE - 1 - r) * BOARD_SIZE + c)\n",
    "                        if piece:\n",
    "                            screen.blit(PIECES[str(piece)], (c * SQ_SIZE, r * SQ_SIZE))\n",
    "\n",
    "                pygame.display.update()\n",
    "\n",
    "                if board.is_game_over():\n",
    "                    game_over = True\n",
    "                    game_running = False\n",
    "                    result = board.result()\n",
    "                    if result == \"0-1\":\n",
    "                        text = FONT.render(\"Black wins\", True, (255, 0, 0))\n",
    "                        black_wins += 1\n",
    "                    elif result == \"1-0\":\n",
    "                        text = FONT.render(\"White wins\", True, (0, 255, 0))\n",
    "                        white_wins += 1\n",
    "                    else:\n",
    "                        text = FONT.render(\"Draw\", True, (128, 128, 128))\n",
    "                        draws += 1\n",
    "\n",
    "                    tab_surface.blit(text, (TAB_WIDTH // 2 - text.get_width() // 2, TAB_HEIGHT // 2 - text.get_height() // 2))\n",
    "                    screen.blit(tab_surface, (WIDTH, 0))\n",
    "                    pygame.display.update()\n",
    "                    pygame.time.delay(3000)\n",
    "                    tab_surface.fill((0, 0, 0), (0, TAB_HEIGHT // 2 - text.get_height() // 2, TAB_WIDTH, text.get_height()))\n",
    "\n",
    "            else:\n",
    "                game_over = False\n",
    "\n",
    "            scoreboard_title = FONT.render(\"SCOREBOARD:\", True, (255, 255, 255))\n",
    "            scoreboard = FONT.render(f\"WHITE {white_wins} - {black_wins} BLACK\", True, (255, 255, 255))\n",
    "            scoreboard_draw = FONT.render(f\"DRAW: {draws}\", True, (255, 255, 255))\n",
    "            tab_surface.fill((0, 0, 0), (0, 0, TAB_WIDTH, 150))\n",
    "            tab_surface.blit(scoreboard_title, (TAB_WIDTH // 2 - scoreboard_title.get_width() // 2, 10))\n",
    "            tab_surface.blit(scoreboard, (TAB_WIDTH // 2 - scoreboard.get_width() // 2, 70))\n",
    "            tab_surface.blit(scoreboard_draw, (TAB_WIDTH // 2 - scoreboard_draw.get_width() // 2, 110))\n",
    "            FONT_SMALL = pygame.font.SysFont(\"arial\", 20)\n",
    "            FONT_MED = pygame.font.SysFont(\"arial\", 24)\n",
    "            # Display current time and additional information\n",
    "            current_time = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S %Z%z\")\n",
    "            time_text = FONT_SMALL.render(f\" Current time: {current_time} KST (UTC+9) \", True, GREY)\n",
    "            morokei_text = FONT_MED.render(\" Morokei's STOCKFISH GRINDER V 7.0 \", True, GREY)\n",
    "            sf_vs_sf_text = FONT_MED.render(\" STOCKFISH 15.0 VS STOCKFISH 15.0 \", True, GREY)\n",
    "\n",
    "            tab_surface.fill((0, 0, 0), (0, TAB_HEIGHT - 130, TAB_WIDTH, 130))\n",
    "            tab_surface.blit(time_text, (TAB_WIDTH // 2 - time_text.get_width() // 2, TAB_HEIGHT - 120))\n",
    "            tab_surface.blit(morokei_text, (TAB_WIDTH // 2 - morokei_text.get_width() // 2, TAB_HEIGHT - 80))\n",
    "            tab_surface.blit(sf_vs_sf_text, (TAB_WIDTH // 2 - sf_vs_sf_text.get_width() // 2, TAB_HEIGHT - 40))\n",
    "            screen.blit(tab_surface, (TAB_X, TAB_Y))\n",
    "            pygame.display.update()\n",
    "            clock.tick(60)\n",
    "\n",
    "    engine.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2edcde",
   "metadata": {},
   "source": [
    "# 게임 실행 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468cfbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def 게임_메뉴():\n",
    "    while True:\n",
    "        print(\"\\n1: 베타제로와 한 판\")\n",
    "        print(\"2: 베타제로 vs 스톡피시\")\n",
    "        print(\"3: 스톡피시와 한 판\")\n",
    "        print(\"4: 베타제로 vs 베타제로\")\n",
    "        print(\"5: 스톡피시 vs 스톡피시\")\n",
    "        print(\"0: 종료\")\n",
    "\n",
    "        choice = input(\"Enter the number (1, 2, 3, 4, 5, or 0): \")\n",
    "\n",
    "        if choice in [\"1\", \"2\", \"3\", \"4\", \"5 \\n\"]:\n",
    "            for i in range(3, 0, -1):\n",
    "                sys.stdout.write(f\"\\r{i}...\")\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(1)\n",
    "\n",
    "            sys.stdout.write(\"\\r\")\n",
    "            sys.stdout.flush()\n",
    "            print(\"\\n\")\n",
    "\n",
    "            if choice == \"1\":\n",
    "                베타제로랑한판()\n",
    "            elif choice == \"2\":\n",
    "                betazero_vs_stockfish()\n",
    "            elif choice == \"3\":\n",
    "                스탁피시랑한판()\n",
    "            elif choice == \"4\":\n",
    "                betazero_vs_betazero()\n",
    "            elif choice == \"5\":\n",
    "                stockfish_vs_stockfish()\n",
    "        elif choice == \"0\":\n",
    "            print(\"종료합니다.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 1, 2, 3, 4, 5, or 0.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_menu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f407a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
